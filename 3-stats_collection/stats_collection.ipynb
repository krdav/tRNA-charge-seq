{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workbookDir: /home/sulab/tRNA-charge-seq/3-stats_collection\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys, os, subprocess, shutil, glob, bz2\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "palette = list(mcolors.TABLEAU_COLORS.keys())\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Navigate back to workbookDir in case of re-running a code block:\n",
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = os.getcwd()\n",
    "print('workbookDir: ' + workbookDir)\n",
    "os.chdir(workbookDir)  # If you changed the current working dir, this will take you back to the workbook dir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "1. gfsa\n",
    "2. hgrewsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAcompRNA = {a: b for a, b in zip('ATGC', 'UACG')}\n",
    "def anticodon2codon(anticodon):\n",
    "    codon = ''.join([DNAcompRNA[b] for b in anticodon[::-1]])\n",
    "    return(codon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that changes from batch to batch:\n",
    "MIN_SCORE = 25\n",
    "#data_folder = 'data/pilot_exp'\n",
    "data_folder = 'data/tRNAseq_lib1'\n",
    "# project_folder = 'projects/pilot_exp'\n",
    "project_folder = 'projects/tRNAseq_lib1'\n",
    "tRNA_database = '../../../2-align_reads/tRNA_database/hg19_mature-tRNA.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that should not change:\n",
    "data_dir = 'stats_collection'\n",
    "align_dir = 'SWalign'\n",
    "umi_dir = 'UMI_trimmed'\n",
    "sample_list = 'sample_list.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read sample information ###\n",
    "sample_df = pd.read_excel('../' + project_folder + '/' + sample_list)\n",
    "sample_dict = {un: {'sample_name': n, 'replicate': r, 'barcode': b} for un, n, r, b in zip(sample_df['sample_name_unique'].values, sample_df['sample_name'].values, sample_df['replicate'].values, sample_df['barcode'].values)}\n",
    "\n",
    "# Create folder for data and stats:\n",
    "os.chdir('../' + data_folder)\n",
    "stats_dir = '../../' + project_folder + '/stats_collection'\n",
    "try:\n",
    "    os.mkdir(stats_dir) # For stats\n",
    "except:\n",
    "    shutil.rmtree(stats_dir)\n",
    "    os.mkdir(stats_dir)\n",
    "# For manipulations and final data:\n",
    "try:\n",
    "    os.mkdir(data_dir) # For data\n",
    "except:\n",
    "    shutil.rmtree(data_dir)\n",
    "    os.mkdir(data_dir)\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tRNA database to find the length of each sequence:\n",
    "tRNA_data = dict()\n",
    "for record in SeqIO.parse(tRNA_database, \"fasta\"):\n",
    "    tRNA_data[record.id] = dict()\n",
    "    tRNA_data[record.id]['len'] = len(record.seq)\n",
    "    tRNA_data[record.id]['codon'] = anticodon2codon(record.id.split('-')[2])\n",
    "    tRNA_data[record.id]['anticodon'] = record.id.split('-')[2]\n",
    "    tRNA_data[record.id]['amino_acid'] = record.id.split('-')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu3\n",
      "HCS1\n",
      "HVP2\n",
      "L-2\n",
      "L-1+2\n",
      "HR40V1\n",
      "Mu2\n",
      "HR80V1\n",
      "HR80S1\n",
      "2U1\n",
      "HR40P2\n",
      "HR40P1\n",
      "Fix1\n",
      "HR40S1\n",
      "2U2\n",
      "HR80V2\n",
      "HVS1\n",
      "Fix2\n",
      "HR30P1\n",
      "L-1\n",
      "BVS2\n",
      "0U1\n",
      "BAV2\n",
      "HR20P1\n",
      "Mu4\n",
      "FT\n",
      "Tu2\n",
      "HR30P2\n",
      "HR20S2\n",
      "Rich-2\n",
      "BVP2\n",
      "HVP1\n",
      "U-1+2\n",
      "BVP1\n",
      "Li3\n",
      "U-1\n",
      "4U1\n",
      "U-2\n",
      "HAV1\n",
      "BVV1\n",
      "HVV2\n",
      "8U1\n",
      "0U2\n",
      "Rich-1+2\n",
      "HVV1\n",
      "HR20V1\n",
      "HR30S2\n",
      "Tu3\n",
      "Li1\n",
      "Li2\n",
      "HCS2\n",
      "Rich-1\n",
      "BVV2\n",
      "Tu1\n",
      "HR30V2\n",
      "Mu1\n",
      "A-2\n",
      "8U2\n",
      "HR20P2\n",
      "A-1+2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2252/3377085850.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh_gz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#SWres = json.loads(fh_gz.read())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mSWres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh_gz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Extract non-template bases from UMI processed reads:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stat_csv_fnam = 'stats_collection.csv.bz2'\n",
    "agg_csv_fnam = 'stats_filtered_CC-CCA-aggregate.csv'\n",
    "try:\n",
    "    pass\n",
    "    os.remove(stat_csv_fnam)\n",
    "    os.remove(agg_csv_fnam)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Open filehandles and printer headers:\n",
    "fh_stats_out = bz2.open(stat_csv_fnam, 'ab')\n",
    "header = ['readID', 'sample_name', 'replicate', 'barcode', 'tRNA_annotation', 'align_score', 'unique_annotation', 'tRNA_annotation_len', 'align_5p_idx', 'align_3p_idx', 'align_5p_nt', 'align_3p_nt', 'codon', 'anticodon', 'amino_acid', '5p_cover', '3p_cover', '5p_non-temp', '3p_non-temp']\n",
    "header_bin = str.encode(','.join(header))\n",
    "fh_stats_out.write(header_bin)\n",
    "\n",
    "fh_agg_out = open(agg_csv_fnam, 'a')\n",
    "agg_cols = ['sample_name', 'replicate', 'barcode', 'tRNA_annotation', 'tRNA_annotation_len', 'unique_annotation', 'align_3p_nt', 'codon', 'anticodon', 'amino_acid', 'count']\n",
    "print(','.join(agg_cols), file=fh_agg_out)\n",
    "\n",
    "# Files to collect stats from:\n",
    "json_files = glob.glob('../' + align_dir + '/*.json.bz2')\n",
    "# print(json_files)\n",
    "for json_file in json_files:\n",
    "    fnam_base = '_'.join(json_file.split('/')[-1].split('_')[0:-1])\n",
    "    uidx = fnam_base.index('UMI')\n",
    "    unique_sample_name = fnam_base[0:uidx-1]\n",
    "    print('Processing: {}'.format(unique_sample_name))\n",
    "    with bz2.open(json_file, 'rt', encoding=\"utf-8\") as fh_gz:\n",
    "        SWres = json.load(fh_gz)\n",
    "    \n",
    "    # Extract non-template bases from UMI processed reads:\n",
    "    fastq_fnam = '../' + umi_dir + '/' + fnam_base + '.fastq.bz2'\n",
    "    with bz2.open(fastq_fnam, 'rt') as fh_gz:\n",
    "        for UMIread in SeqIO.parse(fh_gz, \"fastq\"):\n",
    "            if UMIread.id in SWres:\n",
    "                qpos = SWres[UMIread.id]['qpos'][0]\n",
    "                SWres[UMIread.id]['5p_non-temp'] = str(UMIread.seq)[0:(qpos[0]-1)]\n",
    "                SWres[UMIread.id]['3p_non-temp'] = str(UMIread.seq)[qpos[1]:]\n",
    "\n",
    "    ### Collect stats on a per sample basis and store in tmp file ###\n",
    "    with open('tmp_stat.csv', 'w') as tmp_csv:\n",
    "        print(','.join(header), file=tmp_csv)\n",
    "        for i, readID in enumerate(SWres):\n",
    "            sample_name = sample_dict[unique_sample_name]['sample_name']\n",
    "            replicate = sample_dict[unique_sample_name]['replicate']\n",
    "            barcode = sample_dict[unique_sample_name]['barcode']\n",
    "            tRNA_annotation = SWres[readID]['name']\n",
    "            tRNA_annotation_first = tRNA_annotation.split('@')[0]\n",
    "            align_score = SWres[readID]['score']\n",
    "            unique_annotation = '@' not in tRNA_annotation\n",
    "            tRNA_annotation_len = tRNA_data[tRNA_annotation_first]['len']\n",
    "            align_5p_idx, align_3p_idx = SWres[readID]['dpos'][0]\n",
    "            align_5p_nt = SWres[readID]['qseq'][0]\n",
    "            align_3p_nt = SWres[readID]['qseq'][-1]\n",
    "            # Move index for reads with beta-eliminated A:\n",
    "            if align_3p_idx == (tRNA_annotation_len - 1) and align_3p_nt == 'C':\n",
    "                align_3p_idx += 1\n",
    "            codon = tRNA_data[tRNA_annotation_first]['codon']\n",
    "            anticodon = tRNA_data[tRNA_annotation_first]['anticodon']\n",
    "            amino_acid = tRNA_data[tRNA_annotation_first]['amino_acid']\n",
    "            _5p_cover = align_5p_idx == 1\n",
    "            _3p_cover = align_3p_idx == tRNA_annotation_len\n",
    "            _5p_non_temp = SWres[readID]['5p_non-temp']\n",
    "            _3p_non_temp = SWres[readID]['3p_non-temp']\n",
    "            # Print line to tmp file:\n",
    "            csv_line = ','.join(map(str, [readID, sample_name, replicate, barcode, tRNA_annotation, align_score, unique_annotation, tRNA_annotation_len, align_5p_idx, align_3p_idx, align_5p_nt, align_3p_nt, codon, anticodon, amino_acid, _5p_cover, _3p_cover, _5p_non_temp, _3p_non_temp]))\n",
    "            print(csv_line, file=tmp_csv)\n",
    "    # Append the sample statistics to the final csv file using bz2 compression:\n",
    "    with open('tmp_stat.csv', 'rb') as tmp_csv:\n",
    "        fh_stats_out.write(tmp_csv.read())\n",
    "\n",
    "    ### Aggregate filtered data to count charged/uncharged tRNAs ###\n",
    "    # Read stats from tmp csv file (this is faster than building row by row):\n",
    "    stat_df = pd.read_csv('tmp_stat.csv', keep_default_na=False)\n",
    "    os.remove('tmp_stat.csv')\n",
    "    # 3' must be covered and no 3' non-template bases:\n",
    "    row_mask = (stat_df['3p_cover']) & (stat_df['3p_non-temp'] == '')\n",
    "    agg_df = stat_df.loc[row_mask, agg_cols[0:-1]]\n",
    "    agg_df['count'] = stat_df.loc[row_mask, ['align_3p_nt']]  # dummy for groupby count\n",
    "    agg_df = agg_df.groupby(agg_cols, as_index=False).agg({\"count\": \"count\"})\n",
    "    agg_df.to_csv(fh_agg_out, header=False, index=False, mode='a')\n",
    "\n",
    "fh_stats_out.close()\n",
    "fh_agg_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
