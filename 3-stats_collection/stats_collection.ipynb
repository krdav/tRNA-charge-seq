{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workbookDir: /home/sulab/tRNA-charge-seq/3-stats_collection\n"
     ]
    }
   ],
   "source": [
    "import sys, os, subprocess, shutil, glob, bz2, json\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.ticker as ticker\n",
    "palette = list(mcolors.TABLEAU_COLORS.keys())\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Navigate back to workbookDir in case of re-running a code block:\n",
    "if not 'workbookDir' in globals():\n",
    "    workbookDir = os.getcwd()\n",
    "print('workbookDir: ' + workbookDir)\n",
    "os.chdir(workbookDir)  # If you changed the current working dir, this will take you back to the workbook dir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "1. gfsa\n",
    "2. hgrewsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAcompRNA = {a: b for a, b in zip('ATGC', 'UACG')}\n",
    "def anticodon2codon(anticodon):\n",
    "    codon = ''.join([DNAcompRNA[b] for b in anticodon[::-1]])\n",
    "    return(codon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that changes from batch to batch:\n",
    "CLEAN_DIR = False  # Delete old stats_collection dir\n",
    "OVERWRITE = True   # Overwrite old stat file\n",
    "# Following, not implemented\n",
    "DRY_RUN = False     # Do dry-run, print files to run, nothing else\n",
    "SP_SET = {'mouse', 'human'} # Only run if species is in set\n",
    "\n",
    "\n",
    "#data_folder = 'data/pilot_exp'\n",
    "data_folder = 'data/tRNAseq_lib1'\n",
    "# project_folder = 'projects/pilot_exp'\n",
    "project_folder = 'projects/tRNAseq_lib1'\n",
    "tRNA_database = dict()\n",
    "tRNA_database['human'] = '../../../2-align_reads/tRNA_database/human/hg38-tRNAs.fa'\n",
    "tRNA_database['mouse'] = '../../../2-align_reads/tRNA_database/mouse/mm10-tRNAs.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables that should not change:\n",
    "data_dir = 'stats_collection'\n",
    "align_dir = 'SWalign'\n",
    "umi_dir = 'UMI_trimmed'\n",
    "sample_list = 'sample_list.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read sample information ###\n",
    "sample_df = pd.read_excel('../' + project_folder + '/' + sample_list)\n",
    "sample_dict = {un: {'sample_name': n, 'replicate': r, 'barcode': b, 'species': sp} for un, n, r, b, sp in zip(sample_df['sample_name_unique'].values, sample_df['sample_name'].values, sample_df['replicate'].values, sample_df['barcode'].values, sample_df['species'].values)}\n",
    "\n",
    "# Create folder for data and stats:\n",
    "os.chdir('../' + data_folder)\n",
    "stats_dir = '../../' + project_folder + '/stats_collection'\n",
    "try:\n",
    "    os.mkdir(stats_dir) # For stats\n",
    "except:\n",
    "    if CLEAN_DIR:\n",
    "        shutil.rmtree(stats_dir)\n",
    "        os.mkdir(stats_dir)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# For manipulations and final data:\n",
    "try:\n",
    "    os.mkdir(data_dir) # For data\n",
    "except:\n",
    "    if CLEAN_DIR:\n",
    "        shutil.rmtree(data_dir)\n",
    "        os.mkdir(data_dir)\n",
    "    else:\n",
    "        pass\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tRNA database to find the length of each sequence:\n",
    "tRNA_data = dict()\n",
    "for species in tRNA_database:\n",
    "    for record in SeqIO.parse(tRNA_database[species], \"fasta\"):\n",
    "        tRNA_data[record.id] = dict()\n",
    "        tRNA_data[record.id]['len'] = len(record.seq)\n",
    "        tRNA_data[record.id]['codon'] = anticodon2codon(record.id.split('-')[2])\n",
    "        tRNA_data[record.id]['anticodon'] = record.id.split('-')[2]\n",
    "        tRNA_data[record.id]['amino_acid'] = record.id.split('-')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Rich-1\n",
      "Processing: HR20V2\n",
      "Processing: U-2\n",
      "Processing: HR20P2\n",
      "Processing: HR80S1\n",
      "Processing: U-1+2\n",
      "Processing: CyP\n",
      "Processing: BVV2\n",
      "Processing: BVR2\n",
      "Processing: Rich-NaCl\n",
      "Processing: 8U1\n",
      "Processing: A-1+2\n",
      "Processing: HR40V2\n",
      "Processing: HR80S2\n",
      "Processing: HR20S1\n",
      "Processing: L-2\n",
      "Processing: 2U1\n",
      "Processing: HR80P2\n",
      "Processing: HVV2\n",
      "Processing: A-NaCl\n",
      "Processing: HR30P1\n",
      "Processing: HR40P1\n",
      "Processing: A-2\n",
      "Processing: HR40V1\n",
      "Processing: HVV1\n",
      "Processing: HR40S2\n",
      "Processing: HCS1\n",
      "Processing: 4U1\n",
      "Processing: HR20P1\n",
      "Processing: CyA\n",
      "Processing: HR20V1\n",
      "Processing: HCS2\n",
      "Processing: BVP1\n",
      "Processing: BAR2\n",
      "Processing: Li1\n",
      "Processing: Mu2\n",
      "Processing: Mu4\n",
      "Processing: BVR1\n",
      "Processing: 0U1\n",
      "Processing: L-1\n",
      "Processing: Fix2\n",
      "Processing: HR20S2\n",
      "Processing: HVP2\n",
      "Processing: Tu4\n",
      "Processing: Tu3\n",
      "Processing: HVS1\n",
      "Processing: HR80V2\n",
      "Processing: HR80V1\n",
      "Processing: HR30V1\n",
      "Processing: HR30S1\n",
      "Processing: Li3\n",
      "Processing: U-1\n",
      "Processing: HR30S2\n",
      "Processing: Mu3\n",
      "Processing: HR40S1\n",
      "Processing: L-1+2\n",
      "Processing: HCV1\n",
      "Processing: A-1\n",
      "Processing: BAV2\n",
      "Processing: Rich-1+2\n",
      "Processing: HAS2\n",
      "Processing: Li4\n",
      "Processing: HR40P2\n",
      "Processing: HCV2\n",
      "Processing: BAR1\n",
      "Processing: 8U2\n",
      "Processing: HVS2\n",
      "Processing: BVP2\n",
      "Processing: HVP1\n",
      "Processing: Li2\n",
      "Processing: BAV1\n",
      "Processing: Fix3\n",
      "Processing: Fix1\n",
      "Processing: 4U2\n",
      "Processing: BVV1\n",
      "Processing: HR30P2\n",
      "Processing: HR30V2\n",
      "Processing: HR80P1\n",
      "Processing: Tu2\n",
      "Processing: Tu1\n",
      "Processing: HAV2\n",
      "Processing: U-NaCl\n",
      "Processing: 0U2\n",
      "Processing: 2U2\n",
      "Processing: Mu1\n",
      "Processing: L-NaCl\n",
      "Processing: HAS1\n",
      "Processing: Rich-2\n",
      "Processing: BVS2\n",
      "Processing: FT\n",
      "Processing: HAV1\n",
      "Processing: BVS1\n"
     ]
    }
   ],
   "source": [
    "stat_csv_fnam = 'stats_collection.csv.bz2'\n",
    "agg_csv_fnam = 'stats_filtered_CC-CCA-aggregate.csv'\n",
    "if OVERWRITE:\n",
    "    try:\n",
    "        os.remove(stat_csv_fnam)\n",
    "        os.remove(agg_csv_fnam)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Open filehandles and printer headers:\n",
    "fh_stats_out = bz2.open(stat_csv_fnam, 'ab')\n",
    "header = ['readID', 'sample_name', 'replicate', 'barcode', 'tRNA_annotation', 'align_score', 'unique_annotation', 'tRNA_annotation_len', 'align_5p_idx', 'align_3p_idx', 'align_5p_nt', 'align_3p_nt', 'codon', 'anticodon', 'amino_acid', '5p_cover', '3p_cover', '5p_non-temp', '3p_non-temp']\n",
    "header_bin = str.encode(','.join(header))\n",
    "fh_stats_out.write(header_bin)\n",
    "\n",
    "fh_agg_out = open(agg_csv_fnam, 'a')\n",
    "agg_cols = ['sample_name', 'replicate', 'barcode', 'tRNA_annotation', 'tRNA_annotation_len', 'unique_annotation', 'align_3p_nt', 'codon', 'anticodon', 'amino_acid', 'count']\n",
    "print(','.join(agg_cols), file=fh_agg_out)\n",
    "\n",
    "# Files to collect stats from:\n",
    "json_files = glob.glob('../' + align_dir + '/*.json.bz2')\n",
    "json_files.sort(key=os.path.getmtime)\n",
    "# print(json_files)\n",
    "for json_file in json_files:\n",
    "    fnam_base = '_'.join(json_file.split('/')[-1].split('_')[0:-1])\n",
    "    uidx = fnam_base.index('UMI')\n",
    "    unique_sample_name = fnam_base[0:uidx-1]\n",
    "    print('Processing: {}'.format(unique_sample_name))\n",
    "    with bz2.open(json_file, 'rt', encoding=\"utf-8\") as fh_gz:\n",
    "        SWres = json.load(fh_gz)\n",
    "    \n",
    "    # Extract non-template bases from UMI processed reads:\n",
    "    fastq_fnam = '../' + umi_dir + '/' + fnam_base + '.fastq.bz2'\n",
    "    with bz2.open(fastq_fnam, 'rt') as fh_gz:\n",
    "        for UMIread in SeqIO.parse(fh_gz, \"fastq\"):\n",
    "            if UMIread.id in SWres:\n",
    "                qpos = SWres[UMIread.id]['qpos'][0]\n",
    "                SWres[UMIread.id]['5p_non-temp'] = str(UMIread.seq)[0:(qpos[0]-1)]\n",
    "                SWres[UMIread.id]['3p_non-temp'] = str(UMIread.seq)[qpos[1]:]\n",
    "\n",
    "    ### Collect stats on a per sample basis and store in tmp file ###\n",
    "    with open('tmp_stat.csv', 'w') as tmp_csv:\n",
    "        print(','.join(header), file=tmp_csv)\n",
    "        for i, readID in enumerate(SWres):\n",
    "            sample_name = sample_dict[unique_sample_name]['sample_name']\n",
    "            replicate = sample_dict[unique_sample_name]['replicate']\n",
    "            barcode = sample_dict[unique_sample_name]['barcode']\n",
    "            tRNA_annotation = SWres[readID]['name']\n",
    "            tRNA_annotation_first = tRNA_annotation.split('@')[0]\n",
    "            align_score = SWres[readID]['score']\n",
    "            unique_annotation = '@' not in tRNA_annotation\n",
    "            tRNA_annotation_len = tRNA_data[tRNA_annotation_first]['len']\n",
    "            align_5p_idx, align_3p_idx = SWres[readID]['dpos'][0]\n",
    "            align_5p_nt = SWres[readID]['qseq'][0]\n",
    "            align_3p_nt = SWres[readID]['qseq'][-1]\n",
    "            # Move index for reads with beta-eliminated A:\n",
    "            if align_3p_idx == (tRNA_annotation_len - 1) and align_3p_nt == 'C':\n",
    "                align_3p_idx += 1\n",
    "            codon = tRNA_data[tRNA_annotation_first]['codon']\n",
    "            anticodon = tRNA_data[tRNA_annotation_first]['anticodon']\n",
    "            amino_acid = tRNA_data[tRNA_annotation_first]['amino_acid']\n",
    "            _5p_cover = align_5p_idx == 1\n",
    "            _3p_cover = align_3p_idx == tRNA_annotation_len\n",
    "            _5p_non_temp = SWres[readID]['5p_non-temp']\n",
    "            _3p_non_temp = SWres[readID]['3p_non-temp']\n",
    "            # Print line to tmp file:\n",
    "            csv_line = ','.join(map(str, [readID, sample_name, replicate, barcode, tRNA_annotation, align_score, unique_annotation, tRNA_annotation_len, align_5p_idx, align_3p_idx, align_5p_nt, align_3p_nt, codon, anticodon, amino_acid, _5p_cover, _3p_cover, _5p_non_temp, _3p_non_temp]))\n",
    "            print(csv_line, file=tmp_csv)\n",
    "    # Append the sample statistics to the final csv file using bz2 compression:\n",
    "    with open('tmp_stat.csv', 'rb') as tmp_csv:\n",
    "        fh_stats_out.write(tmp_csv.read())\n",
    "\n",
    "    ### Aggregate filtered data to count charged/uncharged tRNAs ###\n",
    "    # Read stats from tmp csv file (this is faster than building row by row):\n",
    "    stat_df = pd.read_csv('tmp_stat.csv', keep_default_na=False)\n",
    "    os.remove('tmp_stat.csv')\n",
    "    # 3' must be covered and no 3' non-template bases:\n",
    "    row_mask = (stat_df['3p_cover']) & (stat_df['3p_non-temp'] == '')\n",
    "    agg_df = stat_df.loc[row_mask, agg_cols[0:-1]]\n",
    "    agg_df['count'] = stat_df.loc[row_mask, ['align_3p_nt']]  # dummy for groupby count\n",
    "    agg_df = agg_df.groupby(agg_cols, as_index=False).agg({\"count\": \"count\"})\n",
    "    agg_df.to_csv(fh_agg_out, header=False, index=False, mode='a')\n",
    "\n",
    "fh_stats_out.close()\n",
    "fh_agg_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 8U2\n",
      "Processing: A-2\n",
      "Processing: Mu1\n",
      "Processing: HR30V2\n",
      "Processing: Tu1\n",
      "Processing: BVV2\n",
      "Processing: Rich-1\n",
      "Processing: HCS2\n",
      "Processing: Li2\n",
      "Processing: Li1\n",
      "Processing: Tu3\n",
      "Processing: HR30S2\n",
      "Processing: HR20V1\n",
      "Processing: HVV1\n",
      "Processing: Rich-1+2\n",
      "Processing: 0U2\n",
      "Processing: 8U1\n",
      "Processing: HVV2\n",
      "Processing: BVV1\n",
      "Processing: HAV1\n",
      "Processing: U-2\n",
      "Processing: 4U1\n",
      "Processing: U-1\n",
      "Processing: Li3\n",
      "Processing: BVP1\n",
      "Processing: U-1+2\n",
      "Processing: HVP1\n",
      "Processing: BVP2\n",
      "Processing: Rich-2\n",
      "Processing: HR20S2\n",
      "Processing: HR30P2\n",
      "Processing: Tu2\n",
      "Processing: FT\n",
      "Processing: Mu4\n",
      "Processing: HR20P1\n",
      "Processing: BAV2\n",
      "Processing: 0U1\n",
      "Processing: BVS2\n",
      "Processing: L-1\n",
      "Processing: HR30P1\n",
      "Processing: Fix2\n",
      "Processing: HVS1\n",
      "Processing: HR80V2\n",
      "Processing: 2U2\n",
      "Processing: HR40S1\n",
      "Processing: Fix1\n",
      "Processing: HR40P1\n",
      "Processing: HR40P2\n",
      "Processing: 2U1\n",
      "Processing: HR80S1\n",
      "Processing: HR80V1\n",
      "Processing: Mu2\n",
      "Processing: HR40V1\n",
      "Processing: L-1+2\n",
      "Processing: L-2\n",
      "Processing: HVP2\n",
      "Processing: HCS1\n",
      "Processing: Mu3\n"
     ]
    }
   ],
   "source": [
    "# Files to collect stats from:\n",
    "json_files = glob.glob('../' + align_dir + '/*.json.bz2')\n",
    "# print(json_files)\n",
    "file_done = True\n",
    "for json_file in json_files[::-1]:\n",
    "    fnam_base = '_'.join(json_file.split('/')[-1].split('_')[0:-1])\n",
    "    uidx = fnam_base.index('UMI')\n",
    "    unique_sample_name = fnam_base[0:uidx-1]\n",
    "    if unique_sample_name != '8U2' and file_done:\n",
    "        continue\n",
    "    else:\n",
    "        file_done = False\n",
    "    \n",
    "    print('Processing: {}'.format(unique_sample_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
